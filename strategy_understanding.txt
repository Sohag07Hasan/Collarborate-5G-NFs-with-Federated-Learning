In the context of Flower's federated learning framework, the callback functions are generally tied to the concept of rounds rather than epochs. Hereâ€™s a breakdown of the frequency with which each callback function is typically called:

1. on_fit_config_fn
    Frequency: Called at the beginning of each round.
    Purpose: Configures training on the client side, like setting the number of local epochs, learning rate, or any other hyperparameters.
    Control: This function is called once per round for each client selected to participate in that round. It cannot be set to trigger based on epochs.

2. evaluate_fn
    Frequency: Called at the end of each round, after the global model has been updated with the aggregated weights from clients.
    Purpose: Evaluates the global model on a centralized dataset.
    Control: This function is called once per round. You can influence its frequency by adjusting the number of rounds or by choosing not to evaluate in certain rounds, but it's inherently tied to the rounds.

3. evaluate_metrics_aggregation_fn
    Frequency: Called at the end of each evaluation step within a round.
    Purpose: Aggregates the evaluation metrics reported by each client during a round.
    Control: This is automatically called whenever an evaluation is performed, and its frequency is tied to the evaluation steps within rounds.

4. fit_metrics_aggregation_fn
    Frequency: Called at the end of each round after the clients have completed their training and reported their metrics back to the server.
    Purpose: Aggregates the training metrics reported by each client.
    Control: This is also tied to rounds and is called once per round when training is completed.

Custom Frequency Control:
    By Rounds: The frequency of all these callback functions is generally tied to rounds in federated learning. You control the number of rounds using the num_rounds parameter in the server's configuration.
    Custom Scheduling: If you want to customize how often these functions are called, you would need to alter the structure of your rounds. For example, you might skip evaluation or metric aggregation in certain rounds, or introduce custom logic to conditionally call these functions based on specific criteria.
    Epochs: These callback functions do not have direct control over the frequency within epochs because the concept of "epochs" is local to each client. However, you can configure the number of epochs within the on_fit_config_fn to control how long each client trains before it reports back to the server.


------------------- FedAvg Strategy Understanding--------------------------------------------

FedAvg and Weight Averaging:
    After every round, the server receives updated model weights (or gradients) from all participating clients.
    The server averages these weights (using the FedAvg algorithm) to create a new global model.
    This updated global model is then sent back to the clients, which use these new weights to continue training in the next round.

evaluate_metrics_aggregation_fn:
    This function is used only for aggregating evaluation metrics (like accuracy and loss) across all clients to give a "centralized view" of the model's performance.
    It does not affect the weight updates or the model's training process.
    Its sole purpose is to provide a summarized view of how well the model is performing on the distributed data after each round of training. This summary is typically shown in the logs or used for monitoring the training process.

evaluate_fn:
The evaluate_fn function is used to evaluate the global model on a centralized test dataset (if provided).
Similar to evaluate_metrics_aggregation_fn, it does not affect the weight updates.
The main purpose of evaluate_fn is to provide a centralized evaluation of the global model using a validation or test dataset that might not be distributed across the clients.
This is useful for understanding how well the global model is performing on unseen data or a held-out validation set.

So, in summary:
    FedAvg averages weights across clients after each round and updates the global model.
    evaluate_metrics_aggregation_fn provides a summary of the distributed evaluation metrics and has no impact on weight updates.
    evaluate_fn provides centralized evaluation metrics on a test/validation set and also does not affect weight updates.

