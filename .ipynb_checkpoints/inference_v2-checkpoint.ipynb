{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "424c0338-ba52-45c7-b636-7c05ff16352d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sharedrive/PythonCodes/.venv311_new/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score\n",
    "from dataloader import get_evaluation_datasets_by_client  # Assuming this function gets local client datasets\n",
    "from model import Net\n",
    "from collections import OrderedDict\n",
    "from config import NUM_CLASSES, NUM_CLIENTS, GLOBAL_MODEL_PATH, BATCH_SIZE\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import to_tensor\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef994e1c-6907-4e54-8e2a-e623db313884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b96ad0a5-4b91-474f-97ef-a0f36ceacc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_sources = {\n",
    "    'components': [17],\n",
    "    'folds': [1, 2, 3, 4, 5],\n",
    "    #'folds': [1, 2],\n",
    "    'marker': ['o', '-', '^' 'x', '-o-'],\n",
    "    'clients': [1, 2, 3, 4],\n",
    "    'path': './results/original_{0}_fold_{1}'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd56603-bffb-4dee-8e02-0c1b05e790ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5de8f59b-1122-4aab-aec3-84239c5baf44",
   "metadata": {},
   "source": [
    "## 1. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a5a2eaf-1391-4c5e-a4cb-ebc40517757c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the global model from the saved path\n",
    "def load_model(model_path=GLOBAL_MODEL_PATH, num_classes=NUM_CLASSES):\n",
    "    model = Net(num_classes=num_classes)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5e4f19d-02cd-42b4-a9ca-97dadfb76ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on a client's dataset\n",
    "def run_inference(model, dataloader, device):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Get the total number of samples from the DataLoader\n",
    "    total_samples = len(dataloader.dataset)\n",
    "    # Start the timer before the loop\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            features, labels = batch[0].to(device), batch[1].to(device)\n",
    "            outputs = model(features)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # End the timer after the loop\n",
    "    end_time = time.time()    \n",
    "    # Calculate the total inference time\n",
    "    total_inference_time = end_time - start_time    \n",
    "    # Calculate average inference time per sample\n",
    "    #inference_time_per_sample =  total_inference_time * 1000\n",
    "    inference_time_per_sample =  total_inference_time * 1000000 / total_samples\n",
    "    \n",
    "    return np.array(all_preds), np.array(all_labels), f'{inference_time_per_sample:.4f} us'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "106d4a49-75bd-4cc1-b995-0fdc5e26b300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes, title, ax):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "    disp.plot(cmap=plt.cm.Blues, ax=ax)  # Pass ax here directly\n",
    "    ax.set_title(title)  # Optional: Set a title for each subplot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59336a77-e75c-4299-9b8b-d9be081b3510",
   "metadata": {},
   "source": [
    "## 2. Performance/History of Global Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bf58d5-b6f7-4295-8907-44d74e8bdaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729b5d34-d75b-48b9-a7d2-52a86a0cc712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1199c7df-f815-4c52-93f6-f3854ebd9497",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This will read pickle file and return the metrics\n",
    "def parse_history(history_path):\n",
    "    with open(history_path, 'rb') as file:\n",
    "        history = pickle.load(file)\n",
    "        # Extract distributed and centralized losses\n",
    "        loss_distributed = [loss for _, loss in history.losses_distributed]\n",
    "        loss_centralized = [loss for _, loss in history.losses_centralized]\n",
    "        \n",
    "        # Extract accuracy for distributed and centralized evaluation\n",
    "        accuracy_distributed = [acc for _, acc in history.metrics_distributed['accuracy']]\n",
    "        accuracy_centralized = [acc for _, acc in history.metrics_centralized['accuracy']]\n",
    "\n",
    "        return loss_distributed, loss_centralized, accuracy_distributed, accuracy_centralized\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09acce9a-cf00-4638-9b90-b6c8ab25a328",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Parse the Training Time\n",
    "def parse_training_time(time_path):\n",
    "    # Open the text file and read the value\n",
    "    with open(time_path, 'r') as file:\n",
    "    # Read the content of the file and strip any extra spaces or newlines\n",
    "        content = file.read().strip()\n",
    "    # Convert the content to a float, round it, and cast it to an integer\n",
    "    rounded_value = round(float(content))\n",
    "    return int(rounded_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55aeb134-0bf6-4f4f-8018-6cfc65266b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(y_true, y_pred, classes, title, ax):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "    disp.plot(cmap=plt.cm.Blues, ax=ax)  # Pass ax here directly\n",
    "    ax.set_title(title)  # Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc834c8-24d6-466f-a742-4fbba263fb18",
   "metadata": {},
   "source": [
    "### 2.1 Accuracy/Loss vs Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f53caf3-4641-4fb3-a80e-5e6a70b42745",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 23:37:54,030\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold \u001b[38;5;129;01min\u001b[39;00m result_sources\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfolds\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      8\u001b[0m     history_path \u001b[38;5;241m=\u001b[39m result_sources\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mformat(component, fold) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/history.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m        \n\u001b[0;32m----> 9\u001b[0m     l_d, l_c, a_d, a_c \u001b[38;5;241m=\u001b[39m \u001b[43mparse_history\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistory_path\u001b[49m\u001b[43m)\u001b[49m        \n\u001b[1;32m     10\u001b[0m     loss_distributed\u001b[38;5;241m.\u001b[39mappend(l_d)\n\u001b[1;32m     11\u001b[0m     loss_centralized\u001b[38;5;241m.\u001b[39mappend(l_c)\n",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m, in \u001b[0;36mparse_history\u001b[0;34m(history_path)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Extract accuracy for distributed and centralized evaluation\u001b[39;00m\n\u001b[1;32m     10\u001b[0m accuracy_distributed \u001b[38;5;241m=\u001b[39m [acc \u001b[38;5;28;01mfor\u001b[39;00m _, acc \u001b[38;5;129;01min\u001b[39;00m history\u001b[38;5;241m.\u001b[39mmetrics_distributed[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m---> 11\u001b[0m accuracy_centralized \u001b[38;5;241m=\u001b[39m [acc \u001b[38;5;28;01mfor\u001b[39;00m _, acc \u001b[38;5;129;01min\u001b[39;00m \u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics_centralized\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss_distributed, loss_centralized, accuracy_distributed, accuracy_centralized\n",
      "\u001b[0;31mKeyError\u001b[0m: 'accuracy'"
     ]
    }
   ],
   "source": [
    "for component in result_sources.get('components'):    \n",
    "    loss_distributed = [] \n",
    "    loss_centralized = [] \n",
    "    accuracy_distributed =[] \n",
    "    accuracy_centralized = []\n",
    "   \n",
    "    for fold in result_sources.get('folds'):\n",
    "        history_path = result_sources.get('path').format(component, fold) + '/history.pkl'        \n",
    "        l_d, l_c, a_d, a_c = parse_history(history_path)        \n",
    "        loss_distributed.append(l_d)\n",
    "        loss_centralized.append(l_c)\n",
    "        accuracy_distributed.append(a_d)\n",
    "        accuracy_centralized.append(a_c)\n",
    "\n",
    "    history_plots = [\n",
    "        {\n",
    "            'type': 'distributed_loss',\n",
    "            'plot_name': 'Distributed Loss {}',\n",
    "            'x': 'Rounds',\n",
    "            'y': 'Loss',\n",
    "            'plot_position': [0, 0],\n",
    "            'data': loss_distributed,\n",
    "            'colors': ['red', 'brown', 'blue', 'purple', 'green']\n",
    "        },\n",
    "        {\n",
    "            'type': 'accuracy_distributed',\n",
    "            'plot_name': 'Distributed Accuracy {}',\n",
    "            'x': 'Rounds',\n",
    "            'y': 'Accuracy',\n",
    "            'plot_position': [0, 1],\n",
    "            'data': accuracy_distributed,\n",
    "            'colors': ['red', 'brown', 'blue', 'purple', 'green']\n",
    "        },\n",
    "         {\n",
    "            'type': 'centralized_loss',\n",
    "            'plot_name': 'Centralized Loss {}',\n",
    "            'x': 'Rounds',\n",
    "            'y': 'Loss',\n",
    "            'plot_position': [1, 0],\n",
    "            'data': loss_centralized,\n",
    "            'colors': ['red', 'brown', 'blue', 'purple', 'green']\n",
    "        },\n",
    "        {\n",
    "            'type': 'centralized_accuracy',\n",
    "            'plot_name': 'Centralized Accuracy {}',\n",
    "            'x': 'Rounds',\n",
    "            'y': 'Accuracy',\n",
    "            'plot_position': [1, 1],\n",
    "            'data': accuracy_centralized,\n",
    "            'colors': ['red', 'brown', 'blue', 'purple', 'green']\n",
    "        },     \n",
    "      \n",
    "    ]\n",
    "\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(16, 9))  # Adjust the figsize as needed\n",
    "    for plot in  history_plots:\n",
    "        position = plot.get('plot_position')\n",
    "        all_fold_data = plot.get('data')\n",
    "        #print(len(all_fold_data))\n",
    "        for i, data in enumerate(all_fold_data):\n",
    "            rounds = list(range(1, len(data)+1))\n",
    "            ax[position[0], position[1]].plot(rounds, data, label=f'Fold_{i+1}', marker='o', color=plot.get('colors')[i])\n",
    "            ax[position[0], position[1]].set_title(plot.get('plot_name').format(component))\n",
    "            ax[position[0], position[1]].set_xlabel(plot.get('x'))\n",
    "            ax[position[0], position[1]].set_ylabel(plot.get('y'))\n",
    "            ax[position[0], position[1]].legend()\n",
    "            ax[position[0], position[1]].grid(True)\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0331ad99-9689-4909-824a-f4921522fe14",
   "metadata": {},
   "source": [
    "### 2.2 Training Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a2107e6-fb98-4588-8ffa-d206223fe877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Component 17 Fold 1]: 560 Seconds\n",
      "[Component 17 Fold 2]: 560 Seconds\n",
      "[Component 17 Fold 3]: 563 Seconds\n",
      "[Component 17 Fold 4]: 563 Seconds\n",
      "[Component 17 Fold 5]: 560 Seconds\n"
     ]
    }
   ],
   "source": [
    "##Plotting the Time charts\n",
    "for component in result_sources.get('components'):\n",
    "    training_time = []\n",
    "    for fold in result_sources.get('folds'):\n",
    "        ##Parsign the training time\n",
    "        training_time_path = result_sources.get('path').format(component, fold) + '/training_time.txt'\n",
    "        training_time = parse_training_time(training_time_path)\n",
    "        print(f'[Component {component} Fold {fold}]: {training_time} Seconds')\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69b5db2-b662-4581-84fd-87faceaab836",
   "metadata": {},
   "source": [
    "## 3. Accumulate Results\n",
    "- Accumulate all thre results and save in csv file\n",
    "- It also stores values reauired for confusion matrix in a varialbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcf6381e-b55e-4af1-ad87-c274d9c818d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "client_metrics = {\n",
    "    'Component': [],\n",
    "    'Fold': [],\n",
    "    'Client': [],\n",
    "    'Accuracy': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'F1_Score': [],\n",
    "    'Sample_Number': [],\n",
    "    'Inference_Time_Per_Sample': []\n",
    "}\n",
    "\n",
    "classes = np.arange(NUM_CLASSES)  # Define or import this variable\n",
    "\n",
    "def accumulate_results(results, confusion_matrix_data):\n",
    "    components = results.get('components')\n",
    "    folds = results.get('folds')\n",
    "    path = results.get('path')\n",
    "    clients = results.get('clients')\n",
    "     \n",
    "    for component in components:  \n",
    "        for fold in folds:\n",
    "            global_model = path.format(component, fold) + '/' + 'global_model.pth'\n",
    "            history = path.format(component, fold) + '/' + 'history.pkl'\n",
    "            #training_time = path.format(component, fold) + '/' + 'training_time.txt'\n",
    "            \n",
    "            model = load_model(model_path=global_model)\n",
    "            model.to(device)    \n",
    "            num_clients = NUM_CLIENTS  # Define or import this variable    \n",
    "            \n",
    "            for client in clients:                                \n",
    "                testset = get_evaluation_datasets_by_client(client, fold) \n",
    "                #print(testset.shape())\n",
    "                testloader = DataLoader(to_tensor(testset), batch_size=BATCH_SIZE)\n",
    "                preds, labels, inference_time_per_sample = run_inference(model, testloader, device)\n",
    "                client_metrics['Component'].append(component)\n",
    "                client_metrics['Fold'].append(fold)\n",
    "                client_metrics['Client'].append(client)\n",
    "                client_metrics['Accuracy'].append(accuracy_score(labels, preds))\n",
    "                client_metrics['Precision'].append(precision_score(labels, preds))\n",
    "                client_metrics['Recall'].append(recall_score(labels, preds))\n",
    "                client_metrics['F1_Score'].append(f1_score(labels, preds))\n",
    "                client_metrics['Sample_Number'].append(len(labels)),\n",
    "                client_metrics['Inference_Time_Per_Sample'].append(inference_time_per_sample)\n",
    "\n",
    "                #Saving info for confusion matrix\n",
    "                key = f'{component}_{fold}_{client}'\n",
    "                confusion_matrix_data[key] = {\n",
    "                    'preds': preds,\n",
    "                    'labels': labels,\n",
    "                    'classes': np.arange(NUM_CLASSES)\n",
    "                }   \n",
    "\n",
    "    ##Converting into datafram for better visualization\n",
    "    df = pd.DataFrame(client_metrics)\n",
    "    print(df.to_string(index=False))\n",
    "    return df, confusion_matrix_data           \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66c6cb12-f99f-4019-9a45-c9c814003fe7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './results/original_17_fold_1/global_model.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m confusion_matrix_data \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 2\u001b[0m result_df, store_results_df \u001b[38;5;241m=\u001b[39m \u001b[43maccumulate_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult_sources\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfusion_matrix_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 28\u001b[0m, in \u001b[0;36maccumulate_results\u001b[0;34m(results, confusion_matrix_data)\u001b[0m\n\u001b[1;32m     25\u001b[0m history \u001b[38;5;241m=\u001b[39m path\u001b[38;5;241m.\u001b[39mformat(component, fold) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistory.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#training_time = path.format(component, fold) + '/' + 'training_time.txt'\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mglobal_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)    \n\u001b[1;32m     30\u001b[0m num_clients \u001b[38;5;241m=\u001b[39m NUM_CLIENTS  \u001b[38;5;66;03m# Define or import this variable    \u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_path, num_classes)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(model_path\u001b[38;5;241m=\u001b[39mGLOBAL_MODEL_PATH, num_classes\u001b[38;5;241m=\u001b[39mNUM_CLASSES):\n\u001b[1;32m      3\u001b[0m     model \u001b[38;5;241m=\u001b[39m Net(num_classes\u001b[38;5;241m=\u001b[39mnum_classes)\n\u001b[0;32m----> 4\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      5\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/home/sharedrive/PythonCodes/.venv311_new/lib/python3.11/site-packages/torch/serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    789\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 791\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    793\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/home/sharedrive/PythonCodes/.venv311_new/lib/python3.11/site-packages/torch/serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/home/sharedrive/PythonCodes/.venv311_new/lib/python3.11/site-packages/torch/serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 252\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './results/original_17_fold_1/global_model.pth'"
     ]
    }
   ],
   "source": [
    "confusion_matrix_data = {}\n",
    "result_df, store_results_df = accumulate_results(result_sources, confusion_matrix_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcee64a5-4404-4e51-aed9-cbcc52e1d352",
   "metadata": {},
   "source": [
    "## 4. Confusion Matrix (per client per Fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369edecd-71ed-4395-9f49-15e6138f84fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860421bd-e59e-4d79-be72-7bc5aa089873",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = [\n",
    "    {\n",
    "        'client_id': 1,\n",
    "        'plot_name': 'Client 1',\n",
    "        'plot_position': [0, 0]\n",
    "    },\n",
    "    {\n",
    "        'client_id': 2,\n",
    "        'plot_name': 'Client 2',\n",
    "        'plot_position': [0, 1]\n",
    "    },\n",
    "    {\n",
    "        'client_id': 3,\n",
    "        'plot_name': 'Client 3',\n",
    "        'plot_position': [1, 0]\n",
    "    },\n",
    "    {\n",
    "        'client_id': 4,\n",
    "        'plot_name': 'Client 4',\n",
    "        'plot_position': [1, 1]\n",
    "    }   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1b01cb-ef88-4e38-a688-ae3c2e7030ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for component in result_sources.get('components'):\n",
    "    for fold in result_sources.get('folds'):\n",
    "        #print(f\" Plots for Components: {component}, and Folds: {fold}\")\n",
    "        fig, ax = plt.subplots(2, 2, figsize=(12, 10))  # Adjust the figsize as needed\n",
    "        for plot in plots:\n",
    "            client = plot.get('client_id')\n",
    "            key = f'{component}_{fold}_{client}'\n",
    "            data = confusion_matrix_data[key]\n",
    "            title = \"{0} ({1}_{2})\".format(plot['plot_name'], component, fold)\n",
    "            plot_confusion_matrix(data['labels'], data['preds'], data['classes'], title, ax = ax[plot['plot_position'][0], plot['plot_position'][1]])\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        print(\"---------------------------------------------------------------------------------------------------------------------------------\")\n",
    "        print(\"---------------------------------------------------------------------------------------------------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd872bc-f4dd-400d-9546-7751662492bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
